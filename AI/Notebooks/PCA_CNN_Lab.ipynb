{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCA&CNN_Lab.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyODWXgaXJ1EFH3+kjB8kLgN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"hm9Zq1IrmnN-","colab":{"base_uri":"https://localhost:8080/","height":907},"executionInfo":{"status":"ok","timestamp":1592812363923,"user_tz":-420,"elapsed":84253,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"052a4d3b-8aee-40a8-a276-3bca1d31519b"},"source":["!pip install tensorflow==1.15"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 25kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n","\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/tensorboard/\u001b[0m\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 33.4MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.29.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 37.5MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (47.3.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=e55e06521b083dcbe2a4effdddd6e043577ad6879c4e26713d6f6bb3d493c903\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: tensorflow 2.2.0\n","    Uninstalling tensorflow-2.2.0:\n","      Successfully uninstalled tensorflow-2.2.0\n","Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"flikDoExomPc"},"source":["PCA"]},{"cell_type":"code","metadata":{"id":"pT0d-gqjnB-_","executionInfo":{"status":"ok","timestamp":1626944262238,"user_tz":-420,"elapsed":873,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}}},"source":["from sklearn.decomposition import PCA\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","dataset = pd.read_csv('sample_data/california_housing_train.csv')\n","dataset = dataset[['longitude','latitude','median_income','median_house_value']]\n","\n","scaler = MinMaxScaler()\n","dataset= scaler.fit_transform(dataset)\n","\n","print(dataset)\n","\n","pca = PCA(n_components=3)\n","pca = pca.fit(dataset)\n","dataset = pca.transform(dataset)\n","print(dataset)\n","print(dataset.shape)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"8I25gMjKbzpa"},"source":["scaler = MinMaxScaler()\n","dataset= scaler.fit_transform(dataset)\n","\n","print(dataset)\n","\n","pca = PCA(n_components=3)\n","pca = pca.fit(dataset)\n","dataset = pca.transform(dataset)\n","print(dataset)\n","print(dataset.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XRDZAvfyoo3L"},"source":["CNN\n","Convolution Neural Network\n","Dari 2D dibikin jadi 1"]},{"cell_type":"code","metadata":{"id":"V9LvWcBeoojd","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1589268776649,"user_tz":-420,"elapsed":1236,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"d4ff90f7-3ed2-4eb7-f44b-139ed27db0dc"},"source":["import tensorflow as tf\n","from tensorflow.examples.tutorials.mnist import input_data\n","\n","mnist_Data = input_data.read_data_sets('MNIST_Ddata/', one_hot=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","Extracting MNIST_Ddata/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","Extracting MNIST_Ddata/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_Ddata/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_Ddata/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bBkfcTyjtgWB"},"source":["#definisi layer\n","\n","def init_weight(shape):\n","  return tf.Variable(tf.random_normal(shape))\n","\n","def init_bias(shape):\n","  return tf.Variable(tf.random_normal(shape))\n","#buat bikin convolution 2d\n","def conv2d(x,y):\n","  return tf.nn.conv2d(x,y,strides=[1,1,1,1], padding='SAME')#1,1,1,1 itu dimensinya kalo 1 berarti cmn 1\n","\n","def max_pooling(x):\n","  #ksize = [batchsize,height, width, channels]\n","  return tf.nn.max_pool(x, ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n","\n","def conv_layer(x,shape):\n","  weight = init_weight(shape)\n","  bias = init_weight([shape[3]])\n","  out = conv2d(x,weight) + bias\n","  return tf.nn.relu(out)\n","\n","def fully_connected(x, output_size):\n","  input_size= int(x.get_shape()[1])\n","  #sama kek feed dict\n","  weight = init_weight([input_size,output_size])\n","  bias = init_bias([output_size])\n","  return tf.matmul(x,weight)+bias"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-se9KjgUpboT"},"source":["image_width_height = 28\n","\n","x= tf.placeholder(tf.float32,[None, image_width_height*image_width_height])\n","y_true = tf.placeholder(tf.float32, [None,10])\n","\n","x_image = tf.reshape(x,[-1,28,28,1])\n","\n","conv1 = conv_layer(x_image, [5,5,1,32]) # 1 input 32 output\n","pool1 = max_pooling(conv1)\n","\n","# #layer ke2\n","# conv2 = conv_layer(conv1, [5,5,32,64]) # 32 input 64 output\n","# pooll=x_pooling(conv2)\n","\n","# x_flat = tf.reshape(pool2,[-1,7*7*64])# 7 dari itungan 28*28 64 dari output kalo 2 layer\n","# 28*28 totalnya 784 terus 784/maxpooling(window brp 2*2) 784/4 = 196 terus di bagi lagi 4 soalnya ada 2 layer jadi ini 4 bwt layer ke2 jadi 49 terus di akar jadi 7\n","\n","x_flat = tf.reshape(pool1,[-1,14*14*32])# kalo cmn 1 layer\n","\n","y_prediction=  fully_connected(x_flat, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cehxHpOHuvhS","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1589268856409,"user_tz":-420,"elapsed":50671,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"661a98c9-8c8f-4124-9daf-f619b0e49dc8"},"source":["err = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_prediction))\n","opt = tf.train.AdamOptimizer(learning_rate=0.1)\n","\n","train = opt.minimize(err)\n","\n","epoch = 1000\n","\n","saver = tf.train.Saver()\n","\n","\n","with tf.Session() as sess :\n","  sess.run(tf.global_variables_initializer())\n","  for i in range(epoch):\n","    x_batch,y_batch = mnist_Data.train.next_batch(50)\n","    sess.run(train, feed_dict={x:x_batch,y_true:y_batch})\n","    #saver.save(sess,'model.ckpt')#buat savenya\n","    if i%100 ==0:\n","      matches = tf.equal(tf.argmax(y_true,1), tf.argmax(y_prediction,1))\n","      acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n","      print('Iteration:{} Accuraccy:{}'.format(i,sess.run(acc,feed_dict={x:minst_Data.test.images, y_true:minst_Data.test.labels})))\n","\n","#buat load file\n","# with tf.Session() as sess:\n","#    saver.restore(sess, 'model.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Iteration:0 Accuraccy:0.11259999871253967\n","Iteration:100 Accuraccy:0.8539999723434448\n","Iteration:200 Accuraccy:0.8809999823570251\n","Iteration:300 Accuraccy:0.9182000160217285\n","Iteration:400 Accuraccy:0.9144999980926514\n","Iteration:500 Accuraccy:0.9118000268936157\n","Iteration:600 Accuraccy:0.9372000098228455\n","Iteration:700 Accuraccy:0.9071000218391418\n","Iteration:800 Accuraccy:0.9211000204086304\n","Iteration:900 Accuraccy:0.9077000021934509\n"],"name":"stdout"}]}]}