{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Comvis 3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNfoEqX1+Ifqb6Qk6FH0zbt"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"uJ3BwnNHdltQ"},"source":["Find Features"]},{"cell_type":"code","metadata":{"id":"-BjoK6N0dkEu","executionInfo":{"status":"error","timestamp":1603487180102,"user_tz":-420,"elapsed":1806,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"66fb658f-badf-4367-8763-bd219c41e01a","colab":{"base_uri":"https://localhost:8080/","height":180}},"source":["#!/usr/local/bin/python2.7\n","#python findFeatures.py -t dataset/train/\n","\n","import argparse as ap\n","import cv2\n","import numpy as np\n","import os\n","import joblib\n","from scipy.cluster.vq import *\n","\n","from sklearn import preprocessing\n","#from rootsift import RootSIFT\n","#import math\n","\n","# Get the path of the training set\n","parser = ap.ArgumentParser()\n","parser.add_argument(\"-t\", \"--trainingSet\", help=\"Path to Training Set\", required=\"True\")\n","args = vars(parser.parse_args())\n","\n","# Get the training classes names and store them in a list\n","train_path = args[\"trainingSet\"]\n","#train_path = \"dataset/train/\"\n","\n","training_names = os.listdir(train_path)\n","\n","numWords = 1000\n","\n","# Get all the path to the images and save them in a list\n","# image_paths and the corresponding label in image_paths\n","image_paths = []\n","for training_name in training_names:\n","    image_path = os.path.join(train_path, training_name)\n","    image_paths += [image_path]\n","\n","\n","des_list = []\n","\n","\n","for i, image_path in enumerate(image_paths):\n","    im = cv2.imread(image_path)\n","    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n","    print (\"Extract SIFT of %s image, %d of %d images\" %(training_names[i], i, len(image_paths)))\n","    \n","    sift = cv2.xfeatures2d.SIFT_create()\n","    (kps, des) = sift.detectAndCompute(gray, None)\n"," \n","    des_list.append((image_path, des))   \n","    \n","# Stack all the descriptors vertically in a numpy array\n","#downsampling = 1\n","#descriptors = des_list[0][1][::downsampling,:]\n","#for image_path, descriptor in des_list[1:]:\n","#    descriptors = np.vstack((descriptors, descriptor[::downsampling,:]))\n","\n","# Stack all the descriptors vertically in a numpy array\n","descriptors = des_list[0][1]\n","for image_path, descriptor in des_list[1:]:\n","    descriptors = np.vstack((descriptors, descriptor))  \n","\n","# Perform k-means clustering\n","print (\"Start k-means: %d words, %d key points\" %(numWords, descriptors.shape[0]))\n","voc, variance = kmeans(descriptors, numWords, 1) \n","\n","# Calculate the histogram of features\n","im_features = np.zeros((len(image_paths), numWords), \"float32\")\n","for i in range(len(image_paths)):\n","    words, distance = vq(des_list[i][1],voc)\n","    for w in words:\n","        im_features[i][w] += 1\n","\n","print (\"Features =\", im_features)\n","# Perform Tf-Idf vectorization\n","nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n","idf = np.array(np.log((1.0*len(image_paths)+1) / (1.0*nbr_occurences + 1)), 'float32')\n","\n","# Perform L2 normalization\n","im_features = im_features*idf\n","im_features = preprocessing.normalize(im_features, norm='l2')\n","\n","joblib.dump((im_features, image_paths, idf, numWords, voc), \"sift_images.pkl\", compress=3)       \n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["usage: ipykernel_launcher.py [-h] -t TRAININGSET\n","ipykernel_launcher.py: error: the following arguments are required: -t/--trainingSet\n"],"name":"stderr"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"fqi14BOCdr8p"},"source":["Surf Based Search"]},{"cell_type":"code","metadata":{"id":"R_lEr_g0dvWD"},"source":["#!/usr/local/bin/python2.7\n","#python search.py -i dataset/train/ukbench00000.jpg\n","\n","\n","import argparse as ap\n","import cv2\n","#import imutils \n","import numpy as np\n","import os\n","import joblib\n","from scipy.cluster.vq import *\n","\n","from sklearn import preprocessing\n","from pylab import *\n","\n","# Get the path of the training set\n","parser = ap.ArgumentParser()\n","parser.add_argument(\"-i\", \"--image\", help=\"Path to query image\", required=\"True\")\n","args = vars(parser.parse_args())\n","\n","# Get query image path\n","image_path = args[\"image\"]\n","print (image_path)\n","\n","# Load the classifier, class names, scaler, number of clusters and vocabulary \n","im_features, image_paths, idf, numWords, voc = joblib.load(\"surf_images.pkl\")\n","\n","des_list =[]\n","im = cv2.imread(image_path)\n","gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n","\n","surf = cv2.xfeatures2d.SURF_create()\n","(kps, des) = surf.detectAndCompute(gray, None)\n","\n","des_list.append((image_path, des))   \n","    \n","# Stack all the descriptors vertically in a numpy array\n","descriptors = des_list[0][1]\n","\n","# \n","test_features = np.zeros((1, numWords), \"float32\")\n","words, distance = vq(descriptors,voc)\n","for w in words:\n","    test_features[0][w] += 1\n","\n","# Perform Tf-Idf vectorization and L2 normalization\n","test_features = test_features*idf\n","test_features = preprocessing.normalize(test_features, norm='l2')\n","\n","score = np.dot(test_features, im_features.T)\n","rank_ID = np.argsort(-score)\n","\n","print (\"Ranking = \", rank_ID)\n","print (score[0][49])\n","\n","# Visualize the results\n","figure()\n","\n","subplot(3,5,1)\n","imshow(im[:,:,::-1])\n","axis('off')\n","for i, ID in enumerate(rank_ID[0][0:4]):\n","     im = cv2.imread(image_paths[ID])\n","     print (\"index =\", i, \"ID =\",ID)\n","     img = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","     subplot(3,5,i+6)\n","     imshow(img)\n","     axis('off')\n","show()  \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uPKx8poidyPm"},"source":["Sift Based Search"]},{"cell_type":"code","metadata":{"id":"Xvotwkxvd0iX"},"source":["#!/usr/local/bin/python2.7\n","#python search.py -i dataset/train/ukbench00000.jpg\n","\n","import argparse as ap\n","import cv2\n","import numpy as np\n","import joblib\n","from scipy.cluster.vq import *\n","\n","from sklearn import preprocessing\n","#import numpy as np\n","\n","from pylab import *\n","\n","# Get the path of the training set\n","parser = ap.ArgumentParser()\n","parser.add_argument(\"-i\", \"--image\", help=\"Path to query image\", required=\"True\")\n","args = vars(parser.parse_args())\n","\n","# Get query image path\n","image_path = args[\"image\"]\n","print (image_path)\n","\n","# Load the classifier, class names, scaler, number of clusters and vocabulary \n","im_features, image_paths, idf, numWords, voc = joblib.load(\"sift_images.pkl\")\n","\n","\n","des_list =[]\n","im = cv2.imread(image_path)\n","gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n","\n","sift = cv2.xfeatures2d.SIFT_create()\n","(kps, des) = sift.detectAndCompute(gray, None)\n","\n","des_list.append((image_path, des))   \n","    \n","# Stack all the descriptors vertically in a numpy array\n","descriptors = des_list[0][1]\n","\n","# \n","test_features = np.zeros((1, numWords), \"float32\")\n","words, distance = vq(descriptors,voc)\n","for w in words:\n","    test_features[0][w] += 1\n","\n","# Perform Tf-Idf vectorization and L2 normalization\n","test_features = test_features*idf\n","test_features = preprocessing.normalize(test_features, norm='l2')\n","\n","score = np.dot(test_features, im_features.T)\n","rank_ID = np.argsort(-score)\n","\n","print (\"Ranking = \", rank_ID)\n","print (score[0][49])\n","\n","# Visualize the results\n","figure()\n","\n","subplot(3,5,1)\n","imshow(im[:,:,::-1])\n","axis('off')\n","for i, ID in enumerate(rank_ID[0][0:4]):\n","     im = cv2.imread(image_paths[ID])\n","     print (\"index =\", i, \"ID =\",ID)\n","     img = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","     subplot(3,5,i+6)\n","     imshow(img)\n","     axis('off')\n","show()  \n"],"execution_count":null,"outputs":[]}]}