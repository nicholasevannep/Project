{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentiment analysis BERT.ipynb","provenance":[],"authorship_tag":"ABX9TyNIb+SrHWiL+i6cFAQPYwVt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"76749df6cb814d8abfe2846d7c3dcb32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf9b381cca824d31b0198737e95f2e91","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_800592145835435bb00262af51ecb113","IPY_MODEL_193d7c9abbc54b76bce1f03d2e5a4d71"]}},"bf9b381cca824d31b0198737e95f2e91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"800592145835435bb00262af51ecb113":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_befcc36034df4826955be60caf62beb1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_553890e0610d4321b3b23c47b5c2908c"}},"193d7c9abbc54b76bce1f03d2e5a4d71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0f2e117fd63d4584a946056bbafbbc31","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 2.58kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8350e4624a0944478c2fc905f63226fa"}},"befcc36034df4826955be60caf62beb1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"553890e0610d4321b3b23c47b5c2908c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f2e117fd63d4584a946056bbafbbc31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8350e4624a0944478c2fc905f63226fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6025284896cd41fcbf5ccae4ffb57ee7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_627aa5bf31404c2688b302bcc54596c7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2a732fa6e199495e80fca5dfd381407e","IPY_MODEL_538cf16efe3741b2933a2e89acfb9a92"]}},"627aa5bf31404c2688b302bcc54596c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a732fa6e199495e80fca5dfd381407e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_17669d11df184763a92eeefe64490f3c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":536063208,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":536063208,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fcbf0af07ae64b059b0e992dd6eda8a5"}},"538cf16efe3741b2933a2e89acfb9a92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1ec556a581e84ac69703a02196cd5fa4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 536M/536M [00:09&lt;00:00, 58.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08daf9c5dd544a0b96e17f45671a97a0"}},"17669d11df184763a92eeefe64490f3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fcbf0af07ae64b059b0e992dd6eda8a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ec556a581e84ac69703a02196cd5fa4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"08daf9c5dd544a0b96e17f45671a97a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"845ade23ada541a980c3c955e4445544":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_273be2e49c1545b086f5fb97fbe72a56","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_26e277847ebc4f62bbf0d06008322266","IPY_MODEL_74a73d4b33b946a59be2e519cad03513"]}},"273be2e49c1545b086f5fb97fbe72a56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26e277847ebc4f62bbf0d06008322266":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aab2198e51a04c09b3fe9f1fdac637b7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02cdbd49a66c41adbec0fcc9ec03be31"}},"74a73d4b33b946a59be2e519cad03513":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8d9a448f0c154957a473887c26d9a222","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.27MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b5e8802bbe64604b5dcf45d597cf8bf"}},"aab2198e51a04c09b3fe9f1fdac637b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"02cdbd49a66c41adbec0fcc9ec03be31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d9a448f0c154957a473887c26d9a222":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0b5e8802bbe64604b5dcf45d597cf8bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AKV2latRJrv","executionInfo":{"status":"ok","timestamp":1609744942995,"user_tz":-420,"elapsed":3584,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"56db1d49-7c5a-4c2e-f253-67b9c5411b14"},"source":["pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WATzN7eFUTQC"},"source":["Then, we will build our model with the Sequence Classifier and our tokenizer with BERT’s Tokenizer."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237,"referenced_widgets":["76749df6cb814d8abfe2846d7c3dcb32","bf9b381cca824d31b0198737e95f2e91","800592145835435bb00262af51ecb113","193d7c9abbc54b76bce1f03d2e5a4d71","befcc36034df4826955be60caf62beb1","553890e0610d4321b3b23c47b5c2908c","0f2e117fd63d4584a946056bbafbbc31","8350e4624a0944478c2fc905f63226fa","6025284896cd41fcbf5ccae4ffb57ee7","627aa5bf31404c2688b302bcc54596c7","2a732fa6e199495e80fca5dfd381407e","538cf16efe3741b2933a2e89acfb9a92","17669d11df184763a92eeefe64490f3c","fcbf0af07ae64b059b0e992dd6eda8a5","1ec556a581e84ac69703a02196cd5fa4","08daf9c5dd544a0b96e17f45671a97a0","845ade23ada541a980c3c955e4445544","273be2e49c1545b086f5fb97fbe72a56","26e277847ebc4f62bbf0d06008322266","74a73d4b33b946a59be2e519cad03513","aab2198e51a04c09b3fe9f1fdac637b7","02cdbd49a66c41adbec0fcc9ec03be31","8d9a448f0c154957a473887c26d9a222","0b5e8802bbe64604b5dcf45d597cf8bf"]},"id":"r57NlxhzRRPh","executionInfo":{"status":"ok","timestamp":1609744964098,"user_tz":-420,"elapsed":24684,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"69828026-89ac-41b7-fa6b-9bf9b1c559f5"},"source":["\r\n","from transformers import BertTokenizer, TFBertForSequenceClassification\r\n","from transformers import InputExample, InputFeatures\r\n","\r\n","model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\r\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76749df6cb814d8abfe2846d7c3dcb32","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6025284896cd41fcbf5ccae4ffb57ee7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"845ade23ada541a980c3c955e4445544","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yNCS8QULUZYf"},"source":[" BERT model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"grDQX-Q6RSTr","executionInfo":{"status":"ok","timestamp":1609744964099,"user_tz":-420,"elapsed":24683,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"a7fc7b79-e30d-4cca-deac-4b97402c1a06"},"source":["model.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"tf_bert_for_sequence_classification\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  109482240 \n","_________________________________________________________________\n","dropout_37 (Dropout)         multiple                  0         \n","_________________________________________________________________\n","classifier (Dense)           multiple                  1538      \n","=================================================================\n","Total params: 109,483,778\n","Trainable params: 109,483,778\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3hF_CcYcRTJL","executionInfo":{"status":"ok","timestamp":1609744964100,"user_tz":-420,"elapsed":24682,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}}},"source":["\r\n","import tensorflow as tf\r\n","import pandas as pd"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tgQgWUdiUbzg"},"source":["IMDB Dataset"]},{"cell_type":"markdown","metadata":{"id":"snGxVT_RUoU9"},"source":["IMDB Reviews Dataset is a large movie review dataset collected and prepared by Andrew L. Maas from the popular movie rating service, IMDB."]},{"cell_type":"markdown","metadata":{"id":"tzUAnJ-CUrL4"},"source":["Get the Data from the Stanford Repo"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0okb1VDzRZEd","executionInfo":{"status":"ok","timestamp":1609744993874,"user_tz":-420,"elapsed":54452,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"9137f46e-a706-4beb-d1fb-5952f8cc27fc"},"source":["URL = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\r\n","\r\n","dataset = tf.keras.utils.get_file(fname=\"aclImdb_v1.tar.gz\", \r\n","                                  origin=URL,\r\n","                                  untar=True,\r\n","                                  cache_dir='.',\r\n","                                  cache_subdir='')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","84131840/84125825 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5--HAHlQUqAd"},"source":["Remove Unlabeled Reviews\r\n","To remove the unlabeled reviews, we need the following operations. The comments below explain each operation:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Feek2tk1Rans","executionInfo":{"status":"ok","timestamp":1609744995532,"user_tz":-420,"elapsed":56108,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"aedb4d1b-34a3-4340-ec62-ec8d8d76a42e"},"source":["# The shutil module offers a number of high-level \r\n","# operations on files and collections of files.\r\n","import os\r\n","import shutil\r\n","# Create main directory path (\"/aclImdb\")\r\n","main_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\r\n","# Create sub directory path (\"/aclImdb/train\")\r\n","train_dir = os.path.join(main_dir, 'train')\r\n","# Remove unsup folder since this is a supervised learning task\r\n","remove_dir = os.path.join(train_dir, 'unsup')\r\n","shutil.rmtree(remove_dir)\r\n","# View the final train folder\r\n","print(os.listdir(train_dir))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["['unsupBow.feat', 'urls_pos.txt', 'neg', 'labeledBow.feat', 'urls_neg.txt', 'pos', 'urls_unsup.txt']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q1IxDDINU0mx"},"source":["Train and Test Split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxC3AIn7Rbxn","executionInfo":{"status":"ok","timestamp":1609744997661,"user_tz":-420,"elapsed":58235,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"77b03594-56f3-484d-b063-0d3a97f05bd9"},"source":["# We create a training dataset and a validation \r\n","# dataset from our \"aclImdb/train\" directory with a 80/20 split.\r\n","train = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    'aclImdb/train', batch_size=30000, validation_split=0.2, \r\n","    subset='training', seed=123)\r\n","test = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    'aclImdb/train', batch_size=30000, validation_split=0.2, \r\n","    subset='validation', seed=123)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 25000 files belonging to 2 classes.\n","Using 20000 files for training.\n","Found 25000 files belonging to 2 classes.\n","Using 5000 files for validation.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H2mt_W32U5Ac"},"source":["Convert to Pandas to View and Process"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197},"id":"EMYatmnsRdid","executionInfo":{"status":"ok","timestamp":1609745005692,"user_tz":-420,"elapsed":66263,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"e800f45f-feb3-48bc-9f0e-11513a8aaad8"},"source":["\r\n","for i in train.take(1):\r\n","  train_feat = i[0].numpy()\r\n","  train_lab = i[1].numpy()\r\n","\r\n","train = pd.DataFrame([train_feat, train_lab]).T\r\n","train.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\r\n","train['DATA_COLUMN'] = train['DATA_COLUMN'].str.decode(\"utf-8\")\r\n","train.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DATA_COLUMN</th>\n","      <th>LABEL_COLUMN</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Canadian director Vincenzo Natali took the art...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I gave this film 10 not because it is a superb...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I admit to being somewhat jaded about the movi...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>For a long time, 'The Menagerie' was my favori...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A truly frightening film. Feels as if it were ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         DATA_COLUMN LABEL_COLUMN\n","0  Canadian director Vincenzo Natali took the art...            1\n","1  I gave this film 10 not because it is a superb...            1\n","2  I admit to being somewhat jaded about the movi...            1\n","3  For a long time, 'The Menagerie' was my favori...            1\n","4  A truly frightening film. Feels as if it were ...            0"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197},"id":"8Wj8z4GwRd3u","executionInfo":{"status":"ok","timestamp":1609745008469,"user_tz":-420,"elapsed":69038,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"f9cd3a46-865e-4978-b472-195606c53ca0"},"source":["for j in test.take(1):\r\n","  test_feat = j[0].numpy()\r\n","  test_lab = j[1].numpy()\r\n","\r\n","test = pd.DataFrame([test_feat, test_lab]).T\r\n","test.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\r\n","test['DATA_COLUMN'] = test['DATA_COLUMN'].str.decode(\"utf-8\")\r\n","test.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DATA_COLUMN</th>\n","      <th>LABEL_COLUMN</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I can't believe that so much talent can be was...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>This movie blows - let's get that straight rig...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The saddest thing about this \"tribute\" is that...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I'm only rating this film as a 3 out of pity b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Something surprised me about this movie - it w...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         DATA_COLUMN LABEL_COLUMN\n","0  I can't believe that so much talent can be was...            0\n","1  This movie blows - let's get that straight rig...            0\n","2  The saddest thing about this \"tribute\" is that...            0\n","3  I'm only rating this film as a 3 out of pity b...            0\n","4  Something surprised me about this movie - it w...            1"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"hq1rkLXRU94U"},"source":["Creating Input Sequences"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOtP6oUxRful","executionInfo":{"status":"ok","timestamp":1609745008470,"user_tz":-420,"elapsed":69037,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"a620fee4-d816-4b99-f91c-bc9173ecc388"},"source":["InputExample(guid=None,\r\n","             text_a = \"Hello, world\",\r\n","             text_b = None,\r\n","             label = 1)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["InputExample(guid=None, text_a='Hello, world', text_b=None, label=1)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"L-agTtSlU_ml"},"source":["Create 2 main Functions:\r\n","\r\n","1 — convert_data_to_examples: This will accept our train and test datasets and convert each row into an InputExample object.\r\n","\r\n","2 — convert_examples_to_tf_dataset: This function will tokenize the InputExample objects, then create the required input format with the tokenized objects, finally, create an input dataset that we can feed to the model."]},{"cell_type":"code","metadata":{"id":"GN9grldRRgfz","executionInfo":{"status":"ok","timestamp":1609745008471,"user_tz":-420,"elapsed":69036,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}}},"source":["def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \r\n","  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\r\n","                                                          text_a = x[DATA_COLUMN], \r\n","                                                          text_b = None,\r\n","                                                          label = x[LABEL_COLUMN]), axis = 1)\r\n","\r\n","  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\r\n","                                                          text_a = x[DATA_COLUMN], \r\n","                                                          text_b = None,\r\n","                                                          label = x[LABEL_COLUMN]), axis = 1)\r\n","  \r\n","  return train_InputExamples, validation_InputExamples\r\n","\r\n","  train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \r\n","                                                                           test, \r\n","                                                                           'DATA_COLUMN', \r\n","                                                                           'LABEL_COLUMN')\r\n","  \r\n","def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\r\n","    features = [] # -> will hold InputFeatures to be converted later\r\n","\r\n","    for e in examples:\r\n","        # Documentation is really strong for this method, so please take a look at it\r\n","        input_dict = tokenizer.encode_plus(\r\n","            e.text_a,\r\n","            add_special_tokens=True,\r\n","            max_length=max_length, # truncates if len(s) > max_length\r\n","            return_token_type_ids=True,\r\n","            return_attention_mask=True,\r\n","            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\r\n","            truncation=True\r\n","        )\r\n","\r\n","        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\r\n","            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\r\n","\r\n","        features.append(\r\n","            InputFeatures(\r\n","                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\r\n","            )\r\n","        )\r\n","\r\n","    def gen():\r\n","        for f in features:\r\n","            yield (\r\n","                {\r\n","                    \"input_ids\": f.input_ids,\r\n","                    \"attention_mask\": f.attention_mask,\r\n","                    \"token_type_ids\": f.token_type_ids,\r\n","                },\r\n","                f.label,\r\n","            )\r\n","\r\n","    return tf.data.Dataset.from_generator(\r\n","        gen,\r\n","        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\r\n","        (\r\n","            {\r\n","                \"input_ids\": tf.TensorShape([None]),\r\n","                \"attention_mask\": tf.TensorShape([None]),\r\n","                \"token_type_ids\": tf.TensorShape([None]),\r\n","            },\r\n","            tf.TensorShape([]),\r\n","        ),\r\n","    )\r\n","\r\n","\r\n","DATA_COLUMN = 'DATA_COLUMN'\r\n","LABEL_COLUMN = 'LABEL_COLUMN'"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O916IbVdRiIk","executionInfo":{"status":"ok","timestamp":1609745140085,"user_tz":-420,"elapsed":200649,"user":{"displayName":"Nicholas Evan","photoUrl":"","userId":"11340839917959249724"}},"outputId":"e1b0efe4-1880-42e6-dfeb-9cbe05fe8166"},"source":["\r\n","train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\r\n","\r\n","train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\r\n","train_data = train_data.shuffle(100).batch(32).repeat(2)\r\n","\r\n","validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\r\n","validation_data = validation_data.batch(32)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"cPIB0YtxVFR2"},"source":["Configuring the BERT model and Fine-tuning\r\n","\r\n","We will use Adam as our optimizer, CategoricalCrossentropy as our loss function, and SparseCategoricalAccuracy as our accuracy metric. Fine-tuning the model for 2 epochs will give us around 95% accuracy, which is great."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0hje9jRRjk5","outputId":"07feee7c-2dd9-471b-ef9e-ce60dbeb6dc7"},"source":["\r\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \r\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \r\n","              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\r\n","\r\n","model.fit(train_data, epochs=2, validation_data=validation_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa07726d660>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7fa08eab6e58> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa07726d660>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7fa08eab6e58> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fa08c4488c8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: AutoGraph could not transform <function wrap at 0x7fa08c4488c8> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["    413/Unknown - 17972s 43s/step - loss: 0.4413 - accuracy: 0.7850"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3a4wi-zvVMXk"},"source":["Making Predictions"]},{"cell_type":"code","metadata":{"id":"q9v_1gV5RkCZ"},"source":["pred_sentences = ['This was an awesome movie. I watch it twice my time watching this beautiful movie if I have known it was this good',\r\n","                  'One of the worst movies of all time. I cannot believe I wasted two hours of my life for this movie']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTZvUPLaRlsI"},"source":["\r\n","tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\r\n","tf_outputs = model(tf_batch)\r\n","tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\r\n","labels = ['Negative','Positive']\r\n","label = tf.argmax(tf_predictions, axis=1)\r\n","label = label.numpy()\r\n","for i in range(len(pred_sentences)):\r\n","  print(pred_sentences[i], \": \\n\", labels[label[i]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aDRzxTIQRm0T"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uYph0IwJ1ht6"},"source":["https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671"]}]}